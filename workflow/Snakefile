import os


configfile: f"{os.path.dirname(workflow.snakefile)}/../config/default_config.yaml"

include: "sample_table.smk"

rule all_gather:
    input:
        expand("Intermediate/subspecies/gather/{sample}.csv", sample=SAMPLES)


rule sketch_reads:
    input:
        get_quality_controlled_reads,
    output:
        sketch="Intermediate/subspecies/sketch_samples/{sample}.sig",
    conda:
        "envs/sourmash.yaml"
    log:
        "log/subspecies_profiler/sketch_reads/{sample}.log",
    threads: config["threads"]
    resources:
        mem_mb=config["mem_mb"],
        time_min=config["time_min"],
        cpus_per_task=config['threads']
    params:
        kmer_len=config["kmer_len"],
        scaled=config["scaled"],
        mem=int(config["mem_mb"]) * 1000000 * 0.9,
    shell:
        "mkdir -p output/sketch_samples "
        " ; \n "
        "sourmash sketch dna "
        " -p k={params.kmer_len},abund,scaled={params.scaled} "
        " {input}/*.fastq.gz "
        " --merge {wildcards.sample} "
        " -o {output.sketch} &> {log}"

rule gather:
    input:
        sample_sketch= rules.sketch_reads.output
    output:
        gather="Intermediate/subspecies/gather/{sample}.csv"
    conda:
        "envs/sourmash.yaml"
    log:
        "log/subspecies_profiler/gather/{sample}.log",
    threads: 1,
    resources:
        mem_mb=int(config["mem_mb"]),
        time_min=int(config["time_min"])
    params:
        kmer_len=config['kmer_len'],
        scaled=config['scaled'],
        db_path=config['db_path'],
        threshold_bp=config['threshold_bp'],
        scaled_downsample=config['scaled_downsample']
    shell:
        "mkdir -p output/gather && "
        "sourmash gather "
        " -k {params.kmer_len} "
        " --threshold-bp={params.threshold_bp} "
        " --scaled {params.scaled_downsample} "
        " -o {output.gather} "
        " {input.sample_sketch} "
        " {params.db_path} &> {log}"

